# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: -all
#     formats: ipynb,py:percent
#     notebook_metadata_filter: jupytext,-kernelspec,-jupytext.text_representation.jupytext_version
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
# ---

# %% [markdown]
# # ä½ç½®æ•°æ®å±•ç¤ºä¸åˆ†æç³»ç»Ÿ
#
# ## åŠŸèƒ½ï¼šä»JoplinåŠ è½½è§„æ•´ä½ç½®æ•°æ®ï¼Œç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

# %%
import base64
import os
import re
from datetime import datetime, timedelta
from io import BytesIO
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from geopy.distance import great_circle
from sklearn.cluster import DBSCAN

# %%
import pathmagic

with pathmagic.context():
    from func.configpr import getcfpoptionvalue
    from func.first import getdirmain
    from func.jpfuncs import createnote, jpapi, searchnotes, searchnotebook, updatenote_body
    from func.logme import log

# %% [markdown]
# ## é…ç½®å‚æ•°

# %%
# æŠ¥å‘Šå±‚çº§
REPORT_LEVELS = {"monthly": 1, "quarterly": 3, "yearly": 12}

# å¯è§†åŒ–å‚æ•°
PLOT_WIDTH = 10
PLOT_HEIGHT = 8
DPI = 150

# %% [markdown]
# ## æ•°æ®åŠ è½½å‡½æ•°

# %% [markdown]
# ### `load_location_data(scope)`
# åŠ è½½æŒ‡å®šèŒƒå›´çš„ä½ç½®æ•°æ®


# %%
def load_location_data(scope):
    """
    åŠ è½½æŒ‡å®šèŒƒå›´çš„ä½ç½®æ•°æ®
    """
    # è®¡ç®—æ—¶é—´èŒƒå›´
    end_date = datetime.now()
    months = REPORT_LEVELS[scope]
    start_date = end_date - timedelta(days=30 * months)

    # è·å–æœˆä»½åˆ—è¡¨
    date_range = pd.date_range(start_date, end_date, freq="MS")
    monthly_dfs = []

    for date in date_range:
        month_str = date.strftime("%Y%m")

        # ä»Joplinè·å–ä½ç½®æ•°æ®ç¬”è®°
        note_title = f"ä½ç½®æ•°æ®_{month_str}"
        notes = searchnotes(f"title:{note_title}")

        if not notes:
            log.warning(f"æœªæ‰¾åˆ°{month_str}çš„ä½ç½®æ•°æ®ç¬”è®°")
            continue

        note = notes[0]
        resources = jpapi.get_resources(note.id).items

        # æŸ¥æ‰¾ä½ç½®æ•°æ®é™„ä»¶
        location_resource = None
        for res in resources:
            if res.title.endswith(".xlsx"):
                location_resource = res
                break

        if not location_resource:
            log.warning(f"æœªæ‰¾åˆ°{month_str}çš„ä½ç½®æ•°æ®é™„ä»¶")
            continue

        # è¯»å–Excelæ•°æ®
        res_data = jpapi.get_resource_file(location_resource.id)
        df = pd.read_excel(BytesIO(res_data))

        # æ·»åŠ æœˆä»½æ ‡è®°
        df["month"] = month_str
        monthly_dfs.append(df)

    if not monthly_dfs:
        log.warning(f"æœªæ‰¾åˆ°{scope}çš„ä½ç½®æ•°æ®")
        return pd.DataFrame()

    return pd.concat(monthly_dfs).reset_index(drop=True)


# %% [markdown]
# ## æ•°æ®åˆ†æå‡½æ•°

# %% [markdown]
# ### `analyze_location_data(df)`
# åˆ†æä½ç½®æ•°æ®ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ


# %%

def analyze_location_data(df):
    """
    åˆ†æä½ç½®æ•°æ®ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ
    """
    if df.empty:
        return {}
    
    # åŸºç¡€ç»Ÿè®¡
    start_time = df["time"].min()
    end_time = df["time"].max()
    total_points = len(df)
    unique_days = df["time"].dt.date.nunique()
    
    # è®¾å¤‡ä½¿ç”¨ç»Ÿè®¡
    device_stats = df["device_id"].value_counts().to_dict()
    
    # æ´»åŠ¨èŒƒå›´è®¡ç®—ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰
    min_lat, max_lat = df["latitude"].min(), df["latitude"].max()
    min_lon, max_lon = df["longitude"].min(), df["longitude"].max()
    distance_km = great_circle(
        (min_lat, min_lon), 
        (max_lat, max_lon)
    ).kilometers
    
    # è®¡ç®—ä½ç½®èŒƒå›´ï¼ˆä¿®å¤scopeæœªå®šä¹‰é”™è¯¯ï¼‰
    scope = (
        f"çº¬åº¦: {min_lat:.6f}Â° - {max_lat:.6f}Â°, "
        f"ç»åº¦: {min_lon:.6f}Â° - {max_lon:.6f}Â°, "
        f"è·¨åº¦: {distance_km:.2f}å…¬é‡Œ"
    )
    
    # æ—¶é—´è·³è·ƒåˆ†æ
    if "big_gap" in df.columns:
        big_gaps = df[df["big_gap"]]
        gap_stats = {
            "count": len(big_gaps),
            "longest_gap": df["time_diff"].max() if "time_diff" in df.columns else 0
        }
    else:
        gap_stats = {"count": 0, "longest_gap": 0}
    
    # ä½ç½®ç²¾åº¦åˆ†æ
    accuracy_stats = {
        "min": df["accuracy"].min(),
        "max": df["accuracy"].max(),
        "mean": df["accuracy"].mean()
    }
    
    # æ¯æ—¥æ´»åŠ¨æ¨¡å¼
    df["hour"] = df["time"].dt.hour
    hourly_distribution = df["hour"].value_counts().sort_index().to_dict()
    
    # é‡è¦åœ°ç‚¹è¯†åˆ«
    important_places = identify_important_places(df)
    
    return {
        "time_range": (start_time, end_time),
        "total_points": total_points,
        "unique_days": unique_days,
        "device_stats": device_stats,
        "distance_km": distance_km,
        "gap_stats": gap_stats,
        "accuracy_stats": accuracy_stats,
        "hourly_distribution": hourly_distribution,
        "important_places": important_places,
        "scope": scope  # ä½¿ç”¨å·²å®šä¹‰çš„å˜é‡
    }


# %% [markdown]
# ### handle_time_jumps(df)

# %%
def handle_time_jumps(df):
    if df.empty:
        return df

    # ç¡®ä¿æŒ‰æ—¶é—´æ’åº
    df = df.sort_values("time")

    # è®¡ç®—æ—¶é—´å·®ï¼ˆåˆ†é’Ÿï¼‰
    df["time_diff"] = df["time"].diff().dt.total_seconds() / 60

    # æ ‡è®°å¤§æ—¶é—´é—´éš”ï¼ˆ>4å°æ—¶ï¼‰
    df["big_gap"] = df["time_diff"] > 4 * 60

    # æ·»åŠ è¿ç»­æ®µæ ‡è®°
    df["segment"] = df["big_gap"].cumsum()

    return df

# %% [markdown]
# ## é‡è¦åœ°ç‚¹è¯†åˆ«

# %% [markdown]
# ### `identify_important_places(df, radius_km=0.5, min_points=3)`
# è¯†åˆ«é‡è¦åœ°ç‚¹ï¼ˆåœç•™ç‚¹ï¼‰


# %%
def identify_important_places(df, radius_km=0.5, min_points=3):
    """
    è¯†åˆ«é‡è¦åœ°ç‚¹ï¼ˆåœç•™ç‚¹ï¼‰
    """
    if df.empty or "time_diff" not in df.columns:
        return pd.DataFrame()
    required_cols = ["latitude", "longitude", "time_diff"]
    if not all(col in df.columns for col in required_cols):
        return pd.DataFrame()

    # è½¬æ¢åæ ‡ä¸ºå¼§åº¦
    coords = df[["latitude", "longitude"]].values
    kms_per_radian = 6371.0088
    epsilon = radius_km / kms_per_radian

    # DBSCANèšç±»
    db = DBSCAN(
        eps=epsilon, min_samples=min_points, algorithm="ball_tree", metric="haversine"
    ).fit(np.radians(coords))
    df["cluster"] = db.labels_

    # è¿‡æ»¤å™ªå£°ç‚¹
    clustered = df[df["cluster"] != -1]

    if clustered.empty:
        return pd.DataFrame()

    # è®¡ç®—èšç±»ä¸­å¿ƒ
    cluster_centers = (
        clustered.groupby("cluster")
        .agg({"latitude": "mean", "longitude": "mean", "time": "count"})
        .rename(columns={"time": "visit_count"})
        .reset_index()
    )

    # æ·»åŠ åœç•™æ—¶é—´ï¼ˆè¿‘ä¼¼ï¼‰
    cluster_centers["avg_stay_min"] = (
        clustered.groupby("cluster")["time_diff"].mean().values
    )
    if "time_diff" in clustered.columns:
        cluster_centers["avg_stay_min"] = (
            clustered.groupby("cluster")["time_diff"].mean().values
        )
    else:
        cluster_centers["avg_stay_min"] = 0  # é»˜è®¤å€¼
    return cluster_centers.sort_values("visit_count", ascending=False).head(10)


# %% [markdown]
# ## å¯è§†åŒ–å‡½æ•°

# %% [markdown]
# ### `generate_visualizations(df, analysis_results)`
# ç”Ÿæˆä½ç½®æ•°æ®çš„å¯è§†åŒ–å›¾è¡¨


# %%
def generate_visualizations(df, analysis_results):
    """
    ç”Ÿæˆä½ç½®æ•°æ®çš„å¯è§†åŒ–å›¾è¡¨
    """
    images = {}

    # 1. è½¨è¿¹å›¾
    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))

    # æŒ‰è¿ç»­æ®µç»˜åˆ¶ä¸åŒé¢œè‰²
    if "segment" in df.columns:
        for segment in df["segment"].unique():
            seg_df = df[df["segment"] == segment]
            plt.plot(
                seg_df["longitude"],
                seg_df["latitude"],
                alpha=0.7,
                linewidth=1.5,
                label=f"æ®µ {segment}",
            )
    else:
        plt.plot(df["longitude"], df["latitude"], "b-", alpha=0.5, linewidth=1)

    plt.title(f"{analysis_results['scope'].capitalize()}ä½ç½®è½¨è¿¹")
    plt.xlabel("ç»åº¦")
    plt.ylabel("çº¬åº¦")
    plt.grid(True)
    if "segment" in df.columns:
        plt.legend(loc="best")

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=DPI)
    plt.close()
    images["trajectory"] = base64.b64encode(buf.getvalue()).decode("utf-8")

    # 2. æ—¶é—´åˆ†å¸ƒå›¾
    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT - 2))
    hour_counts = analysis_results["hourly_distribution"]
    plt.bar(list(hour_counts.keys()), list(hour_counts.values()), width=0.8)
    plt.title(f"{analysis_results['scope'].capitalize()}ä½ç½®è®°å½•æ—¶é—´åˆ†å¸ƒ")
    plt.xlabel("å°æ—¶")
    plt.ylabel("è®°å½•æ•°é‡")
    plt.xticks(range(0, 24))
    plt.grid(True)

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=DPI)
    plt.close()
    images["time_dist"] = base64.b64encode(buf.getvalue()).decode("utf-8")

    # 3. ç²¾åº¦åˆ†å¸ƒå›¾
    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT - 2))
    plt.hist(df["accuracy"].dropna(), bins=50, alpha=0.7)
    plt.title(f"{analysis_results['scope'].capitalize()}ä½ç½®ç²¾åº¦åˆ†å¸ƒ")
    plt.xlabel("ç²¾åº¦ (ç±³)")
    plt.ylabel("è®°å½•æ•°é‡")
    plt.grid(True)

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=DPI)
    plt.close()
    images["accuracy"] = base64.b64encode(buf.getvalue()).decode("utf-8")

    return images


# %% [markdown]
# ## æ„å»ºæŠ¥å‘Šå†…å®¹

# %% [markdown]
# ### `build_report_content(analysis_results, images)`
# æ„å»ºMarkdownæŠ¥å‘Šå†…å®¹


# %%
def build_report_content(analysis_results, images):
    """
    æ„å»ºMarkdownæŠ¥å‘Šå†…å®¹
    """
    scope = analysis_results["scope"]
    start_time, end_time = analysis_results["time_range"]
    device_stats = analysis_results["device_stats"]
    gap_stats = analysis_results["gap_stats"]
    accuracy_stats = analysis_results["accuracy_stats"]
    hourly_distribution = analysis_results["hourly_distribution"]
    important_places = analysis_results["important_places"]

    # è®¾å¤‡ä½¿ç”¨ç»Ÿè®¡è¡¨
    device_table = "| è®¾å¤‡ID | è®°å½•æ•° | å æ¯” |\n|--------|--------|------|\n"
    total = analysis_results["total_points"]
    for device, count in device_stats.items():
        percent = (count / total) * 100
        device_table += f"| {device} | {count} | {percent:.1f}% |\n"

    # æ—¶é—´åˆ†å¸ƒè¡¨
    time_table = "| å°æ—¶ | è®°å½•æ•° |\n|------|--------|\n"
    for hour in sorted(hourly_distribution.keys()):
        time_table += f"| {hour} | {hourly_distribution[hour]} |\n"

    # é‡è¦åœ°ç‚¹è¡¨
    places_table = ""
    if not important_places.empty:
        places_table = "| çº¬åº¦ | ç»åº¦ | è®¿é—®æ¬¡æ•° | å¹³å‡åœç•™(åˆ†) |\n|------|------|----------|------------|\n"
        for _, row in important_places.iterrows():
            places_table += f"| {row['latitude']:.5f} | {row['longitude']:.5f} | {row['visit_count']} | {row['avg_stay_min']:.1f} |\n"

    # æ„å»ºæŠ¥å‘Š
    report = f"""
# ğŸ“ {scope.capitalize()}ä½ç½®åˆ†ææŠ¥å‘Š 
## æ—¶é—´èŒƒå›´: {start_time.strftime("%Y-%m-%d")} è‡³ {end_time.strftime("%Y-%m-%d")}

### æ¦‚è§ˆç»Ÿè®¡
- **æ€»è®°å½•æ•°**: {analysis_results["total_points"]}
- **è¦†ç›–å¤©æ•°**: {analysis_results["unique_days"]}
- **æ´»åŠ¨èŒƒå›´**: {analysis_results["distance_km"]:.2f}å…¬é‡Œ
- **æ—¶é—´è·³è·ƒæ¬¡æ•°**: {gap_stats["count"]} (æœ€é•¿{gap_stats["longest_gap"]:.1f}å°æ—¶)

### è®¾å¤‡ä½¿ç”¨æƒ…å†µ
{device_table}

### ä½ç½®ç²¾åº¦
- **æœ€å°ç²¾åº¦**: {accuracy_stats["min"]:.1f}ç±³
- **æœ€å¤§ç²¾åº¦**: {accuracy_stats["max"]:.1f}ç±³
- **å¹³å‡ç²¾åº¦**: {accuracy_stats["mean"]:.1f}ç±³

### æ—¶é—´åˆ†å¸ƒ
{time_table}

### é‡è¦åœ°ç‚¹
{places_table}

### å¯è§†åŒ–åˆ†æ
#### ä½ç½®è½¨è¿¹
![è½¨è¿¹å›¾](data:image/png;base64,{images["trajectory"]})

#### æ—¶é—´åˆ†å¸ƒ
![æ—¶é—´åˆ†å¸ƒ](data:image/png;base64,{images["time_dist"]})

#### ç²¾åº¦åˆ†å¸ƒ
![ç²¾åº¦åˆ†å¸ƒ](data:image/png;base64,{images["accuracy"]})
"""
    return report


# %% [markdown]
# ## æ›´æ–°Joplinç¬”è®°

# %% [markdown]
# ### `update_joplin_report(report_content, scope)`
# æ›´æ–°Joplinä½ç½®åˆ†ææŠ¥å‘Š


# %%
def update_joplin_report(report_content, scope):
    """
    æ›´æ–°Joplinä½ç½®åˆ†ææŠ¥å‘Š
    """
    note_title = f"ä½ç½®åˆ†ææŠ¥å‘Š_{scope}"
    existing_notes = searchnotes(f"title:{note_title}")

    if existing_notes:
        note_id = existing_notes[0].id
        updatenote_body(note_id, report_content)
        log.info(f"æ›´æ–°ä½ç½®åˆ†ææŠ¥å‘Š: {note_title}")
    else:
        parent_id = searchnotebook("ewmobile")
        if not parent_id:
            parent_id = createnote(title="ewmobile", notebook=True)
        note_id = createnote(title=note_title, parent_id=parent_id, body=report_content)
        log.info(f"åˆ›å»ºä½ç½®åˆ†ææŠ¥å‘Š: {note_title}")


# %% [markdown]
# ## ä¸»å‡½æ•°

# %% [markdown]
# ### `generate_location_reports()`
# ç”Ÿæˆä¸‰ä¸ªå±‚çº§çš„æŠ¥å‘Šï¼šæœˆæŠ¥ã€å­£æŠ¥ã€å¹´æŠ¥


# %%
def generate_location_reports():
    """
    ç”Ÿæˆä¸‰ä¸ªå±‚çº§çš„æŠ¥å‘Šï¼šæœˆæŠ¥ã€å­£æŠ¥ã€å¹´æŠ¥
    """
    for scope in REPORT_LEVELS.keys():
        log.info(f"å¼€å§‹ç”Ÿæˆ {scope} ä½ç½®æŠ¥å‘Š...")

        # 1. åŠ è½½æ•°æ®
        df = load_location_data(scope)
        if df.empty:
            log.warning(f"è·³è¿‡ {scope} æŠ¥å‘Šï¼Œæ— æ•°æ®")
            continue

        # 2. åˆ†ææ•°æ®
        analysis_results = analyze_location_data(df)

        # 3. ç”Ÿæˆå¯è§†åŒ–
        images = generate_visualizations(df, analysis_results)

        # 4. æ„å»ºæŠ¥å‘Š
        report_content = build_report_content(analysis_results, images)

        # 5. æ›´æ–°Joplinç¬”è®°
        update_joplin_report(report_content, scope)

        log.info(f"{scope.capitalize()}ä½ç½®æŠ¥å‘Šç”Ÿæˆå®Œæˆ")


# %% [markdown]
# ## ä¸»å…¥å£

# %% [markdown]
# ### `main()`
# è„šæœ¬ä¸»å…¥å£

# %%
if __name__ == "__main__":
    log.info("å¼€å§‹ç”Ÿæˆä½ç½®åˆ†ææŠ¥å‘Š...")
    generate_location_reports()
    log.info("ä½ç½®åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
