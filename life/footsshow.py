# -*- coding: utf-8 -*-
# ---
# jupyter:
#   jupytext:
#     cell_metadata_filter: -all
#     formats: ipynb,py:percent
#     notebook_metadata_filter: jupytext,-kernelspec,-jupytext.text_representation.jupytext_version
#     text_representation:
#       extension: .py
#       format_name: percent
#       format_version: '1.3'
# ---

# %% [markdown]
# # ä½ç½®æ•°æ®å±•ç¤ºä¸åˆ†æç³»ç»Ÿ
#
# ## å¼•å…¥åº“

# %%
import base64
import os
import re
from dataclasses import dataclass
from datetime import datetime, timedelta
from io import BytesIO
from pathlib import Path

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sns

# %%
import pathmagic
from geopy.distance import great_circle
from sklearn.cluster import DBSCAN

with pathmagic.context():
    from func.configpr import getcfpoptionvalue
    from func.first import getdirmain
    from func.jpfuncs import (
        add_resource_from_bytes,
        createnote,
        getinivaluefromcloud,
        jpapi,
        searchnotebook,
        searchnotes,
        updatenote_body,
    )
    from func.logme import log
    from func.wrapfuncs import timethis


# %% [markdown]
# ## é…ç½®å‚æ•°

# %%
@dataclass
class Config:
    REPORT_LEVELS: dict = None
    PLOT_WIDTH: int = 10
    PLOT_HEIGHT: int = 8
    DPI: int = 300
    TIME_WINDOW: str = "30min"  # é»˜è®¤2hï¼Œå¯ä»¥ä¸º30minç­‰æ•°å€¼
    STAY_DIST_THRESH: int = 200  # é»˜è®¤200ç±³
    STAY_TIME_THRESH: int = 600  # é»˜è®¤600ç§’ï¼Œååˆ†é’Ÿ

    def __post_init__(self):
        if self.REPORT_LEVELS is None:
            self.REPORT_LEVELS = {
                "monthly": 1,
                "quarterly": 3,
                "yearly": 12,
                "two_yearly": 24,
            }

# %% [markdown]
# ## æ•°æ®åŠ è½½å‡½æ•°

# %% [markdown]
# ### load_location_data(scope, config: Config)
# åŠ è½½æŒ‡å®šèŒƒå›´çš„ä½ç½®æ•°æ®


# %%
def load_location_data(scope, config: Config):
    """
    åŠ è½½æŒ‡å®šèŒƒå›´çš„ä½ç½®æ•°æ®
    """
    # è·å–åŒ…å«å½“å‰æœˆä»½ç¬¬ä¸€å¤©æ—¥æœŸçš„åˆ—è¡¨
    end_date = datetime.now()
    months = config.REPORT_LEVELS[scope]
    start_date = end_date - timedelta(days=30 * months)
    date_range = pd.date_range(start_date, end_date, freq="MS")
    monthly_dfs = []

    for date in date_range:
        month_str = date.strftime("%Y%m")
        note_title = f"ä½ç½®æ•°æ®_{month_str}"
        notes = searchnotes(f"title:{note_title}")

        if not notes:
            log.warning(f"æœªæ‰¾åˆ°{month_str}çš„ä½ç½®æ•°æ®ç¬”è®°")
            continue

        note = notes[0]
        resources = jpapi.get_resources(note.id).items

        location_resource = None
        for res in resources:
            if res.title.endswith(".xlsx"):
                location_resource = res
                break

        if not location_resource:
            log.warning(f"æœªæ‰¾åˆ°{month_str}çš„ä½ç½®æ•°æ®é™„ä»¶")
            continue

        res_data = jpapi.get_resource_file(location_resource.id)
        df = pd.read_excel(BytesIO(res_data))
        df["month"] = month_str
        monthly_dfs.append(df)

    if not monthly_dfs:
        log.warning(f"æœªæ‰¾åˆ°{scope}çš„ä½ç½®æ•°æ®")
        return pd.DataFrame()

    return pd.concat(monthly_dfs).reset_index(drop=True)


# %% [markdown]
# ## æ•°æ®åˆ†æå‡½æ•°

# %% [markdown]
# ### analyze_location_data(df, scope)


# %%
def analyze_location_data(indf, scope):
    """
    åˆ†æä½ç½®æ•°æ®ï¼Œè¿”å›ç»Ÿè®¡ç»“æœ
    ä¿®å¤åˆ—åé—®é¢˜å¹¶æ·»åŠ æ•°æ®é¢„å¤„ç†
    """
    config = Config()
    df = indf.copy()
    # 1. æ•°æ®é¢„å¤„ç†
    # 1.1 è®¾å¤‡èåˆ
    print(
        f"èåˆè®¾å¤‡æ•°æ®å‰å¤§å°ä¸ºï¼š{df.shape[0]}ï¼›èµ·è‡ª{df['time'].min()}ï¼Œæ­¢äº{df['time'].max()}ã€‚"
    )
    print(df.groupby("device_id").count()["time"])
    df = fuse_device_data(df, config)
    print(
        f"èåˆè®¾å¤‡æ•°æ®åå¤§å°ä¸ºï¼š{df.shape[0]}ï¼›èµ·è‡ª{df['time'].min()}ï¼Œæ­¢äº{df['time'].max()}ã€‚"
    )
    print(df.groupby("device_id").count()["time"])

    # 1.2. å¤„ç†æ—¶é—´è·³è·ƒ
    df = handle_time_jumps(df)

    # 1.3. ä½ç½®å¹³æ»‘
    df = smooth_coordinates(df)
    print(
        f"å¤„ç†èåˆè®¾å¤‡ã€æ—¶é—´è·³è·ƒå’Œä½ç½®å¹³æ»‘åè®¾å¤‡æ•°æ®åå¤§å°ä¸ºï¼š{df.shape[0]}ï¼›èµ·è‡ª{df['time'].min()}ï¼Œæ­¢äº{df['time'].max()}ã€‚"
    )
    print(df.groupby("device_id").count()["time"])

    # 1.4. æ·»åŠ å¿…è¦çš„æ—¶é—´å·®åˆ—
    # df["time_diff"] = df["time"].diff().dt.total_seconds().fillna(0)
    # df["timestamp"] = df["time"].dt.strftime("%Y-%m-%d %H:%M:%S")
    # df["time_diff"] = df["time"].diff().dt.total_seconds().fillna(0) / 60

    # 2. è®°å½•è°ƒè¯•ä¿¡æ¯
    print(f"åˆ†æå¯åŠ¨æ—¶æ•°æ®åˆ—ä¸º: {df.columns.tolist()}")

    # 3. æ—¶é—´èŒƒå›´åˆ†æ
    start_time = df["time"].min().strftime("%Y-%m-%d")
    end_time = df["time"].max().strftime("%Y-%m-%d")

    # 4. åŸºæœ¬ç»Ÿè®¡
    total_points = len(df)
    unique_days = df["time"].dt.date.nunique()

    # 5. è®¾å¤‡åˆ†æ
    device_stats = df["device_id"].value_counts().to_dict()

    # 6. è·ç¦»
    min_lat, max_lat = df["latitude"].min(), df["latitude"].max()
    min_lon, max_lon = df["longitude"].min(), df["longitude"].max()
    distance_km = great_circle((min_lat, min_lon), (max_lat, max_lon)).kilometers
    # 7. å¤§è·¨è¶Š
    if "big_gap" in df.columns:
        big_gaps = df[df["big_gap"]]
        gap_stats = {
            "count": len(big_gaps),
            "longest_gap": df["time_diff"].max() if "time_diff" in df.columns else 0,
        }
    else:
        gap_stats = {"count": 0, "longest_gap": 0}

    # 8. å°æ—¶åˆ†å¸ƒ
    df["hour"] = df["time"].dt.hour
    hourly_distribution = df["hour"].value_counts().sort_index().to_dict()

    # 9. ç²¾åº¦åˆ†æ
    accuracy_stats = {
        "min": df["accuracy"].min(),
        "max": df["accuracy"].max(),
        "mean": df["accuracy"].mean(),
    }

    # 10. é‡è¦åœ°ç‚¹åˆ†æ
    clustered = identify_important_places(df)
    important_places = (
        clustered.groupby("cluster")
        .agg(
            {
                "latitude": "mean",
                "longitude": "mean",
            }
        )
        .assign(visit_count=1)
        .assign(avg_stay_min=0)
        .sort_values("visit_count", ascending=False)
        .head(5)
    )

    # 11. åœç•™ç‚¹åˆ†æ
    df = identify_stay_points(df, dist_threshold=350, time_threshold=600)
    # è®¡ç®—åœç•™ç‚¹ç»Ÿè®¡
    stay_stats = {
        "total_stays": df["is_stay"].sum(),
        "avg_duration": df[df["is_stay"]]["duration"].mean() / 60
        if "duration" in df
        else 0,
        "top_locations": df[df["is_stay"]]
        .groupby("cluster")
        .size()
        .nlargest(3)
        .to_dict(),
    }
    stay_stats["resource_id"] = generate_stay_points_map(df, scope, config)

    print(f"åˆ†æå®Œæˆåæ•°æ®åˆ—ä¸º: {df.columns.tolist()}")
    return {
        "scope": scope,
        "time_range": (start_time, end_time),
        "total_points": total_points,
        "unique_days": unique_days,
        "device_stats": device_stats,
        "distance_km": distance_km,
        "gap_stats": gap_stats,
        "accuracy_stats": accuracy_stats,
        "hourly_distribution": hourly_distribution,
        "important_places": important_places.to_dict("records"),
        "stay_stats": stay_stats,
    }

# %% [markdown]
# ### fuse_device_data(df, config: Config)


# %%
@timethis
def fuse_device_data(df, config: Config):
    """å¤šè®¾å¤‡æ•°æ®æ™ºèƒ½èåˆ"""
    print(f"å¤šè®¾å¤‡æ•°æ®æ™ºèƒ½èåˆæ—¶é—´çª—å£ä¸ºï¼š{config.TIME_WINDOW}")
    df["time_window"] = df["time"].dt.floor(config.TIME_WINDOW)
    # print(df.tail())
    fused_points = []

    for window, group in df.groupby("time_window"):
        # ç»™è®¾å¤‡æ´»è·ƒåº¦èµ‹æƒï¼ŒåŸºäºæ—¶é—´çª—å£æ¶µç›–çš„æ•°æ®
        device_activity = {
            device_id: calc_device_activity(group, device_id)
            for device_id in group["device_id"].unique()
        }
        # æ·»åŠ ä½ç½®ç¨³å®šæ€§æ£€æµ‹
        if len(group) > 1:
            # è®¡ç®—ç»„å†…ä½ç½®æ ‡å‡†å·®
            lat_std = group["latitude"].std()
            lon_std = group["longitude"].std()

            # å¦‚æœä½ç½®å˜åŒ–å¾ˆå°ï¼ˆç¨³å®šçŠ¶æ€ï¼‰ï¼Œé€‰æ‹©ç²¾åº¦æœ€é«˜çš„ç‚¹
            if lat_std < 0.002 and lon_std < 0.002:  # çº¦200ç±³ç²¾åº¦
                candidate = group.loc[group["accuracy"].idxmin()]
            else:
                # åŸæœ‰é€‰æ‹©é€»è¾‘
                candidate = group.loc[group["accuracy"].idxmin()]
        else:
            candidate = group.iloc[0]

        active_devices = [
            did
            for did, score in device_activity.items()
            if score > 50 and did in group["device_id"].values
        ]
        if active_devices:
            active_group = group[group["device_id"].isin(active_devices)]
            candidate = active_group.loc[active_group["accuracy"].idxmin()]
        else:
            candidate = group.loc[group["accuracy"].idxmin()]

        if fused_points:
            last_point = fused_points[-1]
            if not check_spatiotemporal_consistency(last_point, candidate):
                group["dist_to_last"] = group.apply(
                    lambda row: great_circle(
                        (last_point.latitude, last_point.longitude),
                        (row.latitude, row.longitude),
                    ).m,
                    axis=1,
                )
                candidate = group.loc[group["dist_to_last"].idxmin()]

        fused_points.append(candidate)
    outdf = pd.DataFrame(fused_points)

    return outdf


# %% [markdown]
# ### calc_device_activity(df, device_id)


# %%
def calc_device_activity(df, device_id):
    """è®¡ç®—è®¾å¤‡æ´»è·ƒåº¦è¯„åˆ†ï¼ˆ0-100ï¼‰"""
    device_data = df[df["device_id"] == device_id].copy()
    if len(device_data) < 2:
        return 0

    total_dist = 0
    prev = None
    for _, row in device_data.iterrows():
        if prev is not None:
            dist = great_circle(
                (prev.latitude, prev.longitude), (row.latitude, row.longitude)
            ).m
            total_dist += dist
        prev = row

    time_span = (
        device_data["time"].max() - device_data["time"].min()
    ).total_seconds() / 3600
    lat_var = device_data["latitude"].var()
    lon_var = device_data["longitude"].var()

    activity_score = min(
        100,
        (total_dist / max(1, time_span)) * 0.7 + (lat_var + lon_var) * 10000 * 0.3,
    )
    return activity_score


# %% [markdown]
# ### calc_device_activity_optimized(df, device_id)

# %%
def calc_device_activity_optimized(df, device_id):
    """ä¼˜åŒ–ç‰ˆè®¾å¤‡æ´»è·ƒåº¦è¯„åˆ†"""
    device_data = df[df["device_id"] == device_id].copy()

    # åŸºç¡€æ ¡éªŒ
    if len(device_data) < 2:
        return 0

    # å‘é‡åŒ–è·ç¦»è®¡ç®—ï¼ˆæ•ˆç‡æå‡10å€+ï¼‰
    coords = device_data[["latitude", "longitude"]].values
    dists = [great_circle(coords[i - 1], coords[i]).m for i in range(1, len(coords))]
    total_dist = sum(dists)

    # æ—¶é—´è·¨åº¦è®¡ç®—ï¼ˆæ·»åŠ æœ€å°é˜ˆå€¼ï¼‰
    time_min = device_data["time"].min()
    time_max = device_data["time"].max()
    time_span = max(0.1, (time_max - time_min).total_seconds() / 3600)  # è‡³å°‘0.1å°æ—¶

    # ä½ç½®å˜åŒ–è®¡ç®—ï¼ˆè½¬æ¢ä¸ºç±³åˆ¶å•ä½ï¼‰
    lat_deg_to_m = 111000  # 1çº¬åº¦â‰ˆ111km
    mean_lat = np.radians(device_data["latitude"].mean())
    lon_deg_to_m = 111000 * np.cos(mean_lat)  # ç»åº¦è·ç¦»éšçº¬åº¦å˜åŒ–

    lat_std_m = device_data["latitude"].std() * lat_deg_to_m
    lon_std_m = device_data["longitude"].std() * lon_deg_to_m
    pos_variation = (lat_std_m**2 + lon_std_m**2) ** 0.5  # ç»¼åˆä½ç½®å˜åŒ–

    # æ”¹è¿›è¯„åˆ†å…¬å¼
    distance_score = min(100, total_dist / time_span) * 0.7  # ç±³/å°æ—¶
    variation_score = min(100, pos_variation / 1000) * 0.3  # åƒç±³çº§å˜åŒ–

    return min(100, distance_score + variation_score)


# %% [markdown]
# ### smooth_coordinates(df, window_size=5)

# %%
def smooth_coordinates(df, window_size=5):
    """
    ä½¿ç”¨æ»‘åŠ¨çª—å£å¹³å‡æ³•å¹³æ»‘ç»çº¬åº¦åæ ‡
    å‚æ•°:
        window_size: æ»‘åŠ¨çª—å£å¤§å°ï¼ˆå¥‡æ•°ï¼‰
    """
    # ç¡®ä¿æŒ‰æ—¶é—´æ’åº
    df = df.sort_values("time")

    # ä½¿ç”¨æ»šåŠ¨çª—å£è®¡ç®—å¹³å‡ä½ç½®
    df["smoothed_lat"] = (
        df["latitude"].rolling(window=window_size, center=True, min_periods=1).mean()
    )

    df["smoothed_lon"] = (
        df["longitude"].rolling(window=window_size, center=True, min_periods=1).mean()
    )

    # å¯¹äºè¾¹ç¼˜ç‚¹ï¼Œä½¿ç”¨åŸå§‹å€¼
    df["smoothed_lat"] = df["smoothed_lat"].fillna(df["latitude"])
    df["smoothed_lon"] = df["smoothed_lon"].fillna(df["longitude"])

    return df

# %% [markdown]
# ### handle_time_jumps(df)


# %%
def handle_time_jumps(df):
    if df.empty:
        return df

    df = df.sort_values("time")
    df["time_diff"] = df["time"].diff().dt.total_seconds() / 60
    df["big_gap"] = df["time_diff"] > 2 * 60
    df["segment"] = df["big_gap"].cumsum()

    return df


# %% [markdown]
# ### check_spatiotemporal_consistency(point1, point2)


# %%
def check_spatiotemporal_consistency(point1, point2):
    """æ£€æŸ¥ä¸¤ç‚¹æ—¶ç©ºä¸€è‡´æ€§"""
    time_diff = abs((point1["time"] - point2["time"]).total_seconds())
    dist = great_circle(
        (point1.latitude, point1.longitude), (point2.latitude, point2.longitude)
    ).m
    max_allowed_dist = min(100, time_diff * 0.5)  # 0.5m/sç§»åŠ¨é€Ÿåº¦
    return dist < max_allowed_dist and time_diff < 300


# %% [markdown]
# ### detect_static_devices(df, var_threshold=0.0002)


# %%
def detect_static_devices(df, var_threshold=0.0002):
    """è¯†åˆ«å¹¶è¿‡æ»¤é™æ€è®¾å¤‡"""
    static_devices = []
    for device_id, device_data in df.groupby("device_id"):
        lat_var = device_data["latitude"].var()
        lon_var = device_data["longitude"].var()

        if lat_var < var_threshold and lon_var < var_threshold:
            static_devices.append(device_id)
            log.info(f"è®¾å¤‡ {device_id} è¢«è¯†åˆ«ä¸ºé™æ€è®¾å¤‡")

    return df[~df["device_id"].isin(static_devices)]


# %% [markdown]
# ### identify_stay_points(df, dist_threshold=350, time_threshold=600)

# %%
def identify_stay_points(df, dist_threshold=350, time_threshold=600):
    # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
    df = df.sort_values("time").reset_index(drop=True)

    # æ·»åŠ å‰ä¸€ä½ç½®åˆ—
    df["prev_lat"] = df["smoothed_lat"].shift(1)
    df["prev_lon"] = df["smoothed_lon"].shift(1)

    # è®¡ç®—è·ç¦»
    df["dist_to_prev"] = df.apply(
        lambda row: great_circle(
            (row["smoothed_lat"], row["smoothed_lon"]),
            (row["prev_lat"], row["prev_lon"]),
        ).meters
        if not pd.isna(row["prev_lat"])
        else 0,
        axis=1,
    )

    # æ·»åŠ æ—¶é—´å·®åˆ—ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    if "time_diff" not in df.columns:
        df["time_diff"] = df["time"].diff().dt.total_seconds().fillna(0)

    # æ ‡è®°åœç•™ç‚¹
    df["is_stay"] = (df["dist_to_prev"] < dist_threshold) & (
        df["time_diff"] > time_threshold
    )

    # åˆ†ç»„è¿ç»­åœç•™ç‚¹
    df["stay_group"] = (df["is_stay"] != df["is_stay"].shift(1)).cumsum()

    # è®¡ç®—æ¯ç»„åœç•™æ—¶é—´
    stay_groups = df[df["is_stay"]].groupby("stay_group")
    df["duration"] = stay_groups["time_diff"].transform("sum")

    # print(df.tail(10))
    return df

# %% [markdown]
# ### `identify_important_places(df, radius_km=0.5, min_points=3)`
# è¯†åˆ«é‡è¦åœ°ç‚¹ï¼ˆåœç•™ç‚¹ï¼‰


# %%
def identify_important_places(df, radius_km=0.5, min_points=3):
    """
    è¯†åˆ«é‡è¦åœ°ç‚¹ï¼ˆåœç•™ç‚¹ï¼‰
    å‡å°èšç±»åŠå¾„ä»¥å¤„ç†ä½ç½®æ‰°åŠ¨
    """
    # ä½¿ç”¨å¹³æ»‘åçš„åæ ‡
    if "smoothed_lat" in df.columns and "smoothed_lon" in df.columns:
        coords = df[["smoothed_lat", "smoothed_lon"]].values
    else:
        coords = df[["latitude", "longitude"]].values

    # å°†åŠå¾„ä»ç±³è½¬æ¢ä¸ºåº¦ï¼ˆè¿‘ä¼¼ï¼‰
    kms_per_radian = 6371.0088
    epsilon = radius_km / kms_per_radian

    # ä½¿ç”¨DBSCANèšç±»
    db = DBSCAN(
        eps=epsilon, min_samples=min_points, algorithm="ball_tree", metric="haversine"
    ).fit(np.radians(coords))

    df["cluster"] = db.labels_

    # åªä¿ç•™æœ‰æ•ˆèšç±»ï¼ˆæ’é™¤å™ªå£°ç‚¹ï¼‰
    clustered = df[df["cluster"] >= 0]

    return clustered


# %%
def generate_visualizations(df, analysis_results, scope):
    """ç”Ÿæˆä½ç½®æ•°æ®çš„å¯è§†åŒ–å›¾è¡¨å¹¶è¿”å›èµ„æºID"""
    resource_ids = {}

    # 1. è½¨è¿¹å›¾
    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT))
    if "segment" in df.columns:
        for segment in df["segment"].unique():
            seg_df = df[df["segment"] == segment]
            plt.plot(
                seg_df["longitude"],
                seg_df["latitude"],
                alpha=0.7,
                linewidth=1.5,
                label=f"æ®µ {segment}",
            )
    else:
        plt.plot(df["longitude"], df["latitude"], "b-", alpha=0.5, linewidth=1)

    plt.title(f"{scope.capitalize()}ä½ç½®è½¨è¿¹")
    plt.xlabel("ç»åº¦")
    plt.ylabel("çº¬åº¦")
    plt.grid(True)
    plt.legend(loc="best")

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=DPI)
    plt.close()
    resource_ids["trajectory"] = add_resource_from_bytes(
        buf.getvalue(), title=f"è½¨è¿¹å›¾_{scope}.png"
    )

    # 2. æ—¶é—´åˆ†å¸ƒå›¾
    plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT - 2))
    hourly_distribution = analysis_results["hourly_distribution"]
    plt.bar(
        list(hourly_distribution.keys()), list(hourly_distribution.values()), width=0.8
    )
    plt.title(f"{scope.capitalize()}ä½ç½®è®°å½•æ—¶é—´åˆ†å¸ƒ")
    plt.xlabel("å°æ—¶")
    plt.ylabel("è®°å½•æ•°é‡")
    plt.xticks(range(0, 24))
    plt.grid(True)

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=DPI)
    plt.close()
    resource_ids["time_dist"] = add_resource_from_bytes(
        buf.getvalue(), title=f"æ—¶é—´åˆ†å¸ƒ_{scope}.png"
    )

    # 3. ç²¾åº¦åˆ†å¸ƒå›¾
    if "accuracy" in df.columns:
        plt.figure(figsize=(PLOT_WIDTH, PLOT_HEIGHT - 2))
        plt.hist(df["accuracy"].dropna(), bins=50, alpha=0.7)
        plt.title(f"{scope.capitalize()}ä½ç½®ç²¾åº¦åˆ†å¸ƒ")
        plt.xlabel("ç²¾åº¦ (ç±³)")
        plt.ylabel("è®°å½•æ•°é‡")
        plt.grid(True)

        buf = BytesIO()
        plt.savefig(buf, format="png", dpi=DPI)
        plt.close()
        resource_ids["accuracy"] = add_resource_from_bytes(
            buf.getvalue(), title=f"ç²¾åº¦åˆ†å¸ƒ_{scope}.png"
        )

    return resource_ids


# %% [markdown]
# ### generate_device_pie_chart(device_stats)

# %%
def generate_device_pie_chart(device_stats):
    """ç”Ÿæˆè®¾å¤‡åˆ†å¸ƒé¥¼å›¾"""
    plt.figure(figsize=(6, 6))
    # labels = [f"è®¾å¤‡{i + 1}" for i in range(len(device_stats))]
    labels = [
        getinivaluefromcloud("device", str(device_id)) for device_id in device_stats
    ]
    sizes = list(device_stats.values())
    plt.pie(sizes, labels=labels, autopct="%1.1f%%", startangle=90)
    plt.axis("equal")

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=120)
    plt.close()
    return add_resource_from_bytes(buf.getvalue(), "è®¾å¤‡åˆ†å¸ƒ.png")


# %% [markdown]
# ### generate_time_heatmap(hourly_distribution)

# %%
def generate_time_heatmap(hourly_distribution):
    """ç”Ÿæˆ24å°æ—¶çƒ­åŠ›å›¾"""
    hours = list(range(24))
    values = [hourly_distribution.get(h, 0) for h in hours]

    plt.figure(figsize=(10, 3))
    plt.bar(hours, values, color="#4c72b0")
    plt.xticks(hours)
    plt.xlabel("å°æ—¶")
    plt.ylabel("è®°å½•æ•°")
    plt.grid(axis="y", alpha=0.3)

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=120)
    plt.close()
    return add_resource_from_bytes(buf.getvalue(), "æ—¶é—´åˆ†å¸ƒçƒ­åŠ›å›¾.png")


# %% [markdown]
# ### generate_geo_link(lat, lon)

# %%
def generate_geo_link(lat, lon):
    """ç”Ÿæˆåœ°å›¾é“¾æ¥"""
    return f" https://www.openstreetmap.org/?mlat={lat}&mlon={lon}&zoom=15"


# %% [markdown]
# ### generate_stay_points_map(df, scope, config)

# %%
def generate_stay_points_map(df, scope, config: Config):
    """ç”Ÿæˆåœç•™ç‚¹åˆ†å¸ƒå›¾"""
    # import matplotlib.pyplot as plt

    plt.figure(figsize=(config.PLOT_WIDTH, config.PLOT_HEIGHT))

    # ç»˜åˆ¶æ‰€æœ‰è½¨è¿¹ç‚¹
    plt.scatter(
        df["longitude"], df["latitude"], c="gray", alpha=0.3, s=5, label="è½¨è¿¹ç‚¹"
    )

    # çªå‡ºæ˜¾ç¤ºåœç•™ç‚¹
    stay_df = df[df["is_stay"]]
    plt.scatter(
        stay_df["longitude"], stay_df["latitude"], c="red", s=50, label="åœç•™ç‚¹"
    )

    # æ ‡æ³¨é«˜é¢‘åœç•™ç‚¹
    top_stays = stay_df.groupby("cluster").size().nlargest(5).index
    for cluster_id in top_stays:
        cluster_df = stay_df[stay_df["cluster"] == cluster_id]
        center_lon = cluster_df["longitude"].mean()
        center_lat = cluster_df["latitude"].mean()
        # ç”¨emojiç¬¦å·ï¼Œç»˜å›¾æ—¶å­—ä½“è²Œä¼¼ä¸æ”¯æŒ
        # plt.text(
        #     center_lon,
        #     center_lat,
        #     f"ğŸ“{cluster_id}",
        #     fontsize=12,
        #     ha="center",
        #     va="bottom",
        # )
        # å…ˆç»˜åˆ¶æ ‡è®°ï¼Œå†æ·»åŠ æ–‡æœ¬
        plt.plot(
            center_lon, center_lat, "o", markersize=8, color="red"
        )  # ç»˜åˆ¶ä¸€ä¸ªåœ†ç‚¹æ ‡è®°
        plt.text(
            center_lon,
            center_lat + 0.001,  # ç¨å¾®åç§»ä»¥é¿å…é‡å 
            str(cluster_id),
            fontsize=10,
            ha="center",
            va="bottom",
        )
        # ç»˜åˆ¶Latexå€’ä¸‰è§’å½¢ï¼Œç©ºå¿ƒ
        # plt.text(
        #     center_lon,
        #     center_lat,
        #     r"$\triangledown$" + f"{cluster_id}",
        #     fontsize=12,
        #     ha="center",
        #     va="bottom",
        # )

    plt.title(f"{scope.capitalize()}åœç•™ç‚¹åˆ†å¸ƒ")
    plt.xlabel("ç»åº¦")
    plt.ylabel("çº¬åº¦")
    plt.legend()

    # ä¿å­˜ä¸ºå›¾ç‰‡èµ„æº
    buf = BytesIO()

    # plt.rcParams["font.sans-serif"] = [
    #     "SimHei",
    #     "DejaVu Sans",
    #     "Noto Sans CJK JP",
    # ]  # æäº†åŠå¤©åº”è¯¥é‚£ä¸ªç³–è‘«èŠ¦emojiå­—ä½“å¯¼è‡´çš„é—®é¢˜ï¼Œç‰¹æ„å¤šæ”¾å‡ ä¸ªå­—ä½“å°è¯•å°è¯•
    # plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
    plt.savefig(buf, format="png", dpi=config.DPI)
    plt.close()
    # buf.seek(0)
    return add_resource_from_bytes(buf.getvalue(), f"åœç•™ç‚¹åˆ†å¸ƒ_{scope}.png")

# %% [markdown]
# ## å¯è§†åŒ–å‡½æ•°

# %% [markdown]
# ### `generate_visualizations(df, analysis_results)`
# ç”Ÿæˆä½ç½®æ•°æ®çš„å¯è§†åŒ–å›¾è¡¨


# %%
def generate_visualizations(df, analysis_results, scope, config: Config):
    """ç”Ÿæˆä½ç½®æ•°æ®çš„å¯è§†åŒ–å›¾è¡¨å¹¶è¿”å›èµ„æºID"""
    resource_ids = {}

    # 1. è½¨è¿¹å›¾
    plt.figure(figsize=(config.PLOT_WIDTH, config.PLOT_HEIGHT))
    if "segment" in df.columns:
        for segment in df["segment"].unique():
            seg_df = df[df["segment"] == segment]
            plt.plot(
                seg_df["longitude"],
                seg_df["latitude"],
                alpha=0.7,
                linewidth=1.5,
                label=f"æ®µ {segment}",
            )
    else:
        plt.plot(df["longitude"], df["latitude"], "b-", alpha=0.5, linewidth=1)

    plt.title(f"{scope.capitalize()}ä½ç½®è½¨è¿¹")
    plt.xlabel("ç»åº¦")
    plt.ylabel("çº¬åº¦")
    plt.grid(True)
    # plt.legend(loc="best")

    buf = BytesIO()
    plt.savefig(buf, format="png", dpi=config.DPI)
    plt.close()
    resource_ids["trajectory"] = add_resource_from_bytes(
        buf.getvalue(), title=f"è½¨è¿¹å›¾_{scope}.png"
    )
    # 2. æ–°å¢è®¾å¤‡åˆ†å¸ƒé¥¼å›¾
    resource_ids["device_dist"] = generate_device_pie_chart(
        analysis_results["device_stats"]
    )

    # 3. æ–°å¢æ—¶é—´åˆ†å¸ƒçƒ­åŠ›å›¾
    resource_ids["time_heatmap"] = generate_time_heatmap(
        analysis_results["hourly_distribution"]
    )

    # 4. ç²¾åº¦åˆ†å¸ƒå›¾ï¼ˆä¼˜åŒ–å±•ç¤ºï¼‰
    if "accuracy" in df.columns:
        plt.figure(figsize=(config.PLOT_WIDTH, config.PLOT_HEIGHT - 2))
        sns.histplot(df["accuracy"].dropna(), bins=30, kde=True, color="#55a868")
        plt.title(f"{scope.capitalize()}å®šä½ç²¾åº¦åˆ†å¸ƒ")
        plt.xlabel("ç²¾åº¦ (ç±³)")
        plt.grid(True, alpha=0.3)
        buf_acc = BytesIO()
        plt.savefig(buf_acc, format="png", dpi=config.DPI)
        plt.close()
        resource_ids["accuracy"] = add_resource_from_bytes(
            buf_acc.getvalue(), f"ç²¾åº¦åˆ†å¸ƒ_{scope}.png"
        )
    # 5. åœç•™ç‚¹åœ°å›¾
    resource_ids["stay_points_map"] = analysis_results["stay_stats"]["resource_id"]

    return resource_ids


# %% [markdown]
# ## æ„å»ºæŠ¥å‘Šå†…å®¹

# %% [markdown]
# ### `build_report_content(analysis_results, resource_ids, scope)`
# æ„å»ºMarkdownæŠ¥å‘Šå†…å®¹


# %%
def build_report_content(analysis_results, resource_ids, scope):
    """ä¼˜åŒ–åçš„æŠ¥å‘Šç»“æ„"""
    # æ ¸å¿ƒæŒ‡æ ‡å¡ç‰‡å¼å¸ƒå±€
    content = f"""
# ğŸ“ {scope.capitalize()}ä½ç½®åˆ†ææŠ¥å‘Š  
**{analysis_results["time_range"][0]} è‡³ {analysis_results["time_range"][1]}**  

## ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡
| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|------|----|------|
| **æ€»è®°å½•** | {analysis_results["total_points"]} | ä½ç½®ç‚¹æ•°é‡ |
| **è¦†ç›–å¤©æ•°** | {analysis_results["unique_days"]} | æ•°æ®å®Œæ•´åº¦ |
| **æ´»åŠ¨åŠå¾„** | {analysis_results["distance_km"]:.2f}km | æœ€å¤§ç§»åŠ¨è·ç¦» |
| **æ—¶é—´æ–­å±‚** | {analysis_results["gap_stats"]["count"]} | æœ€é•¿é—´éš” {analysis_results["gap_stats"]["longest_gap"]:.1f}h |
"""

    # è®¾å¤‡ä½¿ç”¨é¥¼å›¾æ›¿ä»£è¡¨æ ¼
    device_chart = generate_device_pie_chart(analysis_results["device_stats"])
    content += f"""
## ğŸ“± è®¾å¤‡åˆ†å¸ƒ
![è®¾å¤‡åˆ†å¸ƒ](:/{resource_ids["device_dist"]})
"""

    # ç²¾åº¦æŒ‡æ ‡å¡ç‰‡
    content += f"""
## ğŸ¯ å®šä½ç²¾åº¦
| æŒ‡æ ‡ | å€¼ |
|------|----|
| **æœ€ä½³ç²¾åº¦** | {analysis_results["accuracy_stats"]["min"]:.1f}m |
| **æœ€å·®ç²¾åº¦** | {analysis_results["accuracy_stats"]["max"]:.1f}m |
| **å¹³å‡ç²¾åº¦** | {analysis_results["accuracy_stats"]["mean"]:.1f}m |
"""

    # æ—¶é—´åˆ†å¸ƒçƒ­åŠ›å›¾
    content += f"""
## ğŸ•’ æ—¶é—´åˆ†å¸ƒ
![æ—¶é—´åˆ†å¸ƒ](:/{resource_ids["time_heatmap"]})
"""

    # æ–°å¢åœç•™ç‚¹åˆ†æéƒ¨åˆ†
    content += f"""
## ğŸ›‘ åœç•™ç‚¹åˆ†æ

| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |
|---|---|---|
| æ€»åœç•™æ¬¡æ•° | {analysis_results["stay_stats"]["total_stays"]} | è¯†åˆ«åˆ°çš„åœç•™ç‚¹æ•°é‡ |
| å¹³å‡åœç•™æ—¶é•¿ | {analysis_results["stay_stats"]["avg_duration"]:.1f}åˆ†é’Ÿ | æ¯æ¬¡åœç•™çš„å¹³å‡æ—¶é—´ |
| é«˜é¢‘åœç•™ç‚¹ | {len(analysis_results["stay_stats"]["top_locations"])}å¤„ | è®¿é—®æœ€é¢‘ç¹çš„åœ°ç‚¹ |
"""

    # æ·»åŠ åœç•™ç‚¹åˆ†å¸ƒå›¾
    content += f"""
### åœç•™ç‚¹åˆ†å¸ƒå›¾
![åœç•™ç‚¹åˆ†å¸ƒ](:/{resource_ids["stay_points_map"]})
"""

    # ç²¾é€‰é‡è¦åœ°ç‚¹ï¼ˆå‰3ï¼‰
    content += """
## ğŸŒ å…³é”®åœ°ç‚¹
| ä½ç½® | è®¿é—® | åœç•™ | åæ ‡ |
|------|------|------|------|"""
    for i, place in enumerate(analysis_results["important_places"][:3]):
        visit_count = int(place["visit_count"])
        lat = place["latitude"]
        lon = place["longitude"]
        content += f"""
| **åœ°ç‚¹{i + 1}** | {visit_count}æ¬¡ | {place["avg_stay_min"]:.1f}åˆ† | [{lat}, {lon}]({generate_geo_link(lat, lon)}) |"""

    # å¯è§†åŒ–åˆ†æ
    content += f"""
## ğŸ“ˆ ç©ºé—´åˆ†æ
### ç§»åŠ¨è½¨è¿¹
![ç§»åŠ¨è½¨è¿¹](:/{resource_ids["trajectory"]})

### ä½ç½®ç²¾åº¦åˆ†å¸ƒ
![ä½ç½®è¿›åº¦åˆ†å¸ƒ](:/{resource_ids["accuracy"]})
"""
    return content


# %% [markdown]
# ## æ›´æ–°Joplinç¬”è®°

# %% [markdown]
# ### `update_joplin_report(report_content, scope)`
# æ›´æ–°Joplinä½ç½®åˆ†ææŠ¥å‘Š


# %%
def update_joplin_report(report_content, scope):
    """
    æ›´æ–°Joplinä½ç½®åˆ†ææŠ¥å‘Š
    """
    note_title = f"ä½ç½®åˆ†ææŠ¥å‘Š_{scope}"
    existing_notes = searchnotes(f"title:{note_title}")

    if existing_notes:
        note_id = existing_notes[0].id
        # æ›´æ–°ç¬”è®°å†…å®¹
        updatenote_body(note_id, report_content)
    else:
        parent_id = searchnotebook("ewmobile")
        if not parent_id:
            parent_id = createnote(title="ewmobile", notebook=True)

        # åˆ›å»ºæ–°ç¬”è®°
        note_id = createnote(title=note_title, parent_id=parent_id, body=report_content)


# %% [markdown]
# ## ä¸»å‡½æ•°

# %% [markdown]
# ### `generate_location_reports()`
# ç”Ÿæˆä¸‰ä¸ªå±‚çº§çš„æŠ¥å‘Šï¼šæœˆæŠ¥ã€å­£æŠ¥ã€å¹´æŠ¥


# %%
@timethis
def generate_location_reports(config: Config):
    """
    ç”Ÿæˆä¸‰ä¸ªå±‚çº§çš„æŠ¥å‘Šï¼šæœˆæŠ¥ã€å­£æŠ¥ã€å¹´æŠ¥
    """
    for scope in list(config.REPORT_LEVELS.keys())[:]:
        log.info(f"å¼€å§‹ç”Ÿæˆ {scope} ä½ç½®æŠ¥å‘Š...")

        # 1. åŠ è½½æ•°æ®
        df = load_location_data(scope, config)
        if df.empty:
            log.warning(f"è·³è¿‡ {scope} æŠ¥å‘Šï¼Œæ— æ•°æ®")
            continue

        # åˆ†ææ•°æ®
        print(f"è¿›å…¥æ±‡æ€»è¾“å‡ºæ—¶æ•°æ®åˆ—å‘½ä»¤åˆ—è¡¨ä¸ºï¼š{df.columns.tolist()}")
        analysis_results = analyze_location_data(df, scope)

        # ç”Ÿæˆå¯è§†åŒ–å¹¶è·å–èµ„æºID
        resource_ids = generate_visualizations(df, analysis_results, scope, config)

        # æ„å»ºæŠ¥å‘Š
        report_content = build_report_content(analysis_results, resource_ids, scope)

        # æ›´æ–°ç¬”è®°å¹¶é™„åŠ èµ„æº
        update_joplin_report(report_content, scope)


# %% [markdown]
# ## ä¸»å…¥å£

# %% [markdown]
# ### `main()`
# è„šæœ¬ä¸»å…¥å£

# %%
if __name__ == "__main__":
    log.info("å¼€å§‹ç”Ÿæˆä½ç½®åˆ†ææŠ¥å‘Š...")
    generate_location_reports(Config())
    log.info("ä½ç½®åˆ†ææŠ¥å‘Šç”Ÿæˆå®Œæˆ")
